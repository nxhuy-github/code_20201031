{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-ae932be897c3>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers: common sets of useful operations\n",
    "\n",
    "Tensorflow provides both a set of many common layers as a well as easy ways for us to write **our own application-specific layers** either **from scratch** or as the composition of existing layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.46782422, -0.05257368, -0.25427076,  0.32925683, -0.09659088,\n",
       "          0.32908106, -0.13641864,  0.2193982 ,  0.4319312 , -0.33939832],\n",
       "        [ 0.04265887,  0.20727038, -0.24140438,  0.05396444,  0.23715138,\n",
       "          0.5543944 , -0.13134867,  0.3376338 , -0.563634  ,  0.27744722],\n",
       "        [-0.20655927, -0.171323  ,  0.23290563, -0.10670441,  0.55393   ,\n",
       "         -0.4798702 ,  0.38878685,  0.00894934,  0.23586816,  0.2853368 ],\n",
       "        [ 0.3723325 ,  0.24434882, -0.51813656,  0.5341199 ,  0.5725302 ,\n",
       "          0.09141684,  0.58302504,  0.4946534 , -0.44481516,  0.39735776],\n",
       "        [-0.1548793 , -0.13500199, -0.54266936, -0.31376085,  0.5232113 ,\n",
       "         -0.04429144,  0.5632487 ,  0.59331197, -0.536319  ,  0.34284735]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       "array([[-0.46782422, -0.05257368, -0.25427076,  0.32925683, -0.09659088,\n",
       "         0.32908106, -0.13641864,  0.2193982 ,  0.4319312 , -0.33939832],\n",
       "       [ 0.04265887,  0.20727038, -0.24140438,  0.05396444,  0.23715138,\n",
       "         0.5543944 , -0.13134867,  0.3376338 , -0.563634  ,  0.27744722],\n",
       "       [-0.20655927, -0.171323  ,  0.23290563, -0.10670441,  0.55393   ,\n",
       "        -0.4798702 ,  0.38878685,  0.00894934,  0.23586816,  0.2853368 ],\n",
       "       [ 0.3723325 ,  0.24434882, -0.51813656,  0.5341199 ,  0.5725302 ,\n",
       "         0.09141684,  0.58302504,  0.4946534 , -0.44481516,  0.39735776],\n",
       "       [-0.1548793 , -0.13500199, -0.54266936, -0.31376085,  0.5232113 ,\n",
       "        -0.04429144,  0.5632487 ,  0.59331197, -0.536319  ,  0.34284735]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing custom layers\n",
    "\n",
    "The best way is extending the `tf.keras.Layer` class and implementing:\n",
    "- `__init__`, where we can do all **input-independent** initialization\n",
    "- `build`, where we know the shapes of the input tensors and can do the rest of the initialization\n",
    "- `call`, where we do the forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[\n",
    "            int(input_shape[-1]),\n",
    "            self.num_outputs\n",
    "        ])\n",
    "        \n",
    "    def call(self, _input):\n",
    "        return tf.matmul(_input, self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = MyDenseLayer(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_dense_layer/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "_ = layer(tf.zeros([10, 5]))\n",
    "\n",
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Composing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "        \n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding=\"same\")\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "        \n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "    \n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f7fdefd8c50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f7fdefd87b8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f7ff9ab3860>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f8027256c50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f80272637b8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f7ff81d5d30>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_identity_block\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  8         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 2)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, None, 2)     8         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 3)     9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, None, 3)     12        \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
