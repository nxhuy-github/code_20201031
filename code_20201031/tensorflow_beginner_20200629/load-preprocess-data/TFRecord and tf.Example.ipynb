{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TFRecord` format is a simple format for storing a sequence of binary records.\n",
    "\n",
    "The `tf.Example` message (or protobuf) is a flexible message type that represents a `{\"string\": value}` mapping. It is designed for use with TensorFlow and is used throughout the higher-level APIs such as TFX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.Example`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types for `tf.Example`\n",
    "\n",
    "Fundamentally, a `tf.Example` is a `{\"string\": tf.train.Feature}` mapping.\n",
    "\n",
    "The `tf.train.Feature` message type can accept one of the following three types\n",
    "- `tf.train.BytesList`\n",
    "    - string\n",
    "    - byte\n",
    "- `tf.train.FloatList`\n",
    "    - float (float32)\n",
    "    - double (float64)\n",
    "- `tf.train.Int64List`\n",
    "    - bool\n",
    "    - enum\n",
    "    - int32\n",
    "    - uint32\n",
    "    - int64\n",
    "    - uint64\n",
    "    \n",
    "In order to convert a standard TensorFlow type to a `tf.Example`-compatible `tf.train.Feature`, we can use the shortcut functions below. Note that each function takes a scalar input value and returns a `tf.train.Feature` containing one of the three `list` types above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"test_bytes\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature('test_bytes'.encode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float_list {\n",
      "  value: 2.7182817459106445\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "print(_float_feature(np.exp(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))\n",
    "#print(_int64_feature(1.0)) # Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All proto messages can be **serialized to a binary-string** using the `.SerializeToString` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x12\\x06\\n\\x04T\\xf8-@'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = _float_feature(np.exp(1))\n",
    "feature.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `tf.Example` message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of observations in the dataset.\n",
    "n_observations = int(1e4)\n",
    "n_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ..., False,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boolean feature, encoded as False or True\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "feature0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, ..., 1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer feature, random from 0 to 4.\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'goat', b'horse', b'goat', ..., b'dog', b'chicken', b'horse'],\n",
       "      dtype='|S7')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# String feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0210511 ,  0.82749023, -0.69820937, ..., -1.93800073,\n",
       "        1.22599431,  1.55077696])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float feature, from a standard normal distribution\n",
    "feature3 = np.random.randn(n_observations)\n",
    "feature3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these features can be coerced into a `tf.Example`-compatible type using one of `_bytes_feature`, `_float_feature`, `_int64_feature`. We can then create a `tf.Example` message from these encoded features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    feature = {\n",
    "        \"feature0\": _int64_feature(feature0),\n",
    "        \"feature1\": _int64_feature(feature1),\n",
    "        \"feature2\": _bytes_feature(feature2),\n",
    "        \"feature3\": _float_feature(feature3)\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04[\\xd3|?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an example observation from the dataset.\n",
    "example_observation = []\n",
    "\n",
    "serialized_example = serialize_example(False, 4, b'goat', 0.9876)\n",
    "serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "features {\n",
       "  feature {\n",
       "    key: \"feature0\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 0\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature1\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 4\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature2\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"goat\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"feature3\"\n",
       "    value {\n",
       "      float_list {\n",
       "        value: 0.9876000285148621\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To decode the message use the tf.train.Example.FromString method\n",
    "example_proto = tf.train.Example.FromString(serialized_example)\n",
    "example_proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords format details\n",
    "\n",
    "A TFRecord file contains a **sequence of records**. The file can only be read sequentially.\n",
    "\n",
    "Each record contains a byte-string, for the data-payload, plus the data-length, and CRC32C (32-bit CRC using the Castagnoli polynomial) hashes for integrity checking.\n",
    "\n",
    "Each record is stored in the following formats\n",
    "\n",
    "`uint64 length\n",
    "uint32 masked_crc32_of_length\n",
    "byte   data[length]\n",
    "uint32 masked_crc32_of_data\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The records are concatenated together to produce the file. CRCs are described here, and the mask of a CRC is:\n",
    "\n",
    "masked_crc = ((crc >> 15) | (crc << 17)) + 0xa282ead8ul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord files using `tf.data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a TFRecord file\n",
    "\n",
    "The easiest way to **get the data into a dataset** is to use the `from_tensor_slices` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 4, ..., 1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.from_tensor_slices(feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), (), (), ()), types: (tf.bool, tf.int64, tf.string, tf.float64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applied to a tuple of arrays, it returns a dataset of tuples\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices((feature0, feature1, feature2, feature3))\n",
    "features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(False, shape=(), dtype=bool)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(b'goat', shape=(), dtype=string)\n",
      "tf.Tensor(0.021051098542752146, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# View data\n",
    "for f0, f1, f2, f3 in features_dataset.take(1):\n",
    "    print(f0)\n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    print(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `tf.data.Dataset.map` method to apply a function to each element of a Dataset.\n",
    "\n",
    "The mapped function must operate in TensorFlow graph modeâ€”it must operate on and return `tf.Tensors`. A non-tensor function, like `serialize_example`, can be wrapped with `tf.py_function` to make it compatible.\n",
    "\n",
    "Using `tf.py_function` **requires to specify the shape and type information** that is otherwise unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_serialize_example(f0, f1, f2, f3):\n",
    "    tf_string = tf.py_function(\n",
    "        serialize_example,\n",
    "        inp=(f0, f1, f2, f3),\n",
    "        Tout=tf.string\n",
    "    )\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04Zs\\xac<'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_serialize_example(f0, f1, f2, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply this function to each element in the dataset\n",
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for features in features_dataset:\n",
    "        yield serialize_example(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    output_types=tf.string,\n",
    "    output_shapes=()\n",
    ")\n",
    "serialized_features_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And write them to a TFRecord file\n",
    "filename = 'test.tfrecord'\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a TFRecord file\n",
    "\n",
    "We can also read the TFRecord file using the `tf.data.TFRecordDataset` class.\n",
    "\n",
    "More information on consuming `TFRecord` files using tf.data can be found here.\n",
    "\n",
    "Using `TFRecordDatasets` can be useful for standardizing input data and optimizing performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the dataset contains serialized `tf.train.Example` messages. When iterated over it returns these as scalar string tensors.\n",
    "\n",
    "Use the `.take` method to only show the first 10 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04Zs\\xac<'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04f\\xd6S?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nR\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xd9\\xbd2\\xbf\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xe5\\xbb\\x89?\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nQ\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x13\\n\\x08feature2\\x12\\x07\\n\\x05\\n\\x03cat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x17)\\x86?'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nU\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xe4\\xf0\\x16>\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nU\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x17\\n\\x08feature2\\x12\\x0b\\n\\t\\n\\x07chicken\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x043\\x91\\x82\\xbf\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nR\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\n\\x14\\n\\x08feature2\\x12\\x08\\n\\x06\\n\\x04goat\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\xec\\x94E\\xbf'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04\\x07\\x91\\x86\\xbf\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03'>\n",
      "<tf.Tensor: shape=(), dtype=string, numpy=b'\\nS\\n\\x11\\n\\x08feature0\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\n\\x11\\n\\x08feature1\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x15\\n\\x08feature2\\x12\\t\\n\\x07\\n\\x05horse\\n\\x14\\n\\x08feature3\\x12\\x08\\x12\\x06\\n\\x04,Q\\x1d\\xbf'>\n"
     ]
    }
   ],
   "source": [
    "for raw_record in raw_dataset.take(10):\n",
    "    print(repr(raw_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tensors can be parsed using the function below. Note that the `feature_description` is necessary here because **datasets use graph-execution**, and need this description to build their shape and type signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature0': FixedLenFeature(shape=[], dtype=tf.int64, default_value=0),\n",
       " 'feature1': FixedLenFeature(shape=[], dtype=tf.int64, default_value=0),\n",
       " 'feature2': FixedLenFeature(shape=[], dtype=tf.string, default_value=''),\n",
       " 'feature3': FixedLenFeature(shape=[], dtype=tf.float32, default_value=0.0)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a description of the features\n",
    "feature_description = {\n",
    "    'feature0': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature1': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'feature2': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'feature3': tf.io.FixedLenFeature([], tf.float32, default_value=0.0),\n",
    "}\n",
    "feature_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, use `tf.parse` example to parse the whole batch at once. Apply this function to each item in the dataset using the `tf.data.Dataset.map` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {feature0: (), feature1: (), feature2: (), feature3: ()}, types: {feature0: tf.int64, feature1: tf.int64, feature2: tf.string, feature3: tf.float32}>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = raw_dataset.map(_parse_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use eager execution to display** the observations in the dataset. There are 10,000 observations in this dataset, but we will only display the first 10. The data is displayed as a dictionary of features. Each item is a `tf.Tensor`, and the numpy element of this tensor displays the value of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.021051098>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.8274902>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-0.69820935>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=1.0760466>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'cat'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=1.048129>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=0.1474033>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'chicken'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-1.0200561>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'goat'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-0.7718036>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-1.0513009>}\n",
      "{'feature0': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'feature1': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'feature2': <tf.Tensor: shape=(), dtype=string, numpy=b'horse'>, 'feature3': <tf.Tensor: shape=(), dtype=float32, numpy=-0.61451983>}\n"
     ]
    }
   ],
   "source": [
    "for parsed_record in parsed_dataset.take(10):\n",
    "    print(repr(parsed_record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `tf.parse_example` function unpacks the `tf.Example` fields into standard tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
