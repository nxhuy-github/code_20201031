{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model progress can be saved during - and after - training. This means a model can resume where it left off and avoid long training times. Saving also means you can share your model and others can recreate your work. When publishing research models and techniques, most machine learning practitioners share:\n",
    "- code to create the model, and\n",
    "- the trained weights, or parameters, for the model\n",
    "\n",
    "\n",
    "Summary:\n",
    "- save weights during training: `tf.keras.callbacks.ModelCheckpoint` (with some options)\n",
    "- save entire model at the end: `model.save` (SavedModel or HDF5 format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options\n",
    "\n",
    "There are different ways to save Tensorflow models - depending on the API you're using. This guide uses `tf.keras`, a high-level API to build and train models in Tensorflow. For other approaches, see the Tensorflow **Save and Restore** guide or **Saving in eager**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Train images shape: (1000, 784)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Train images shape: {train_images.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels  = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28*28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28*28) / 255.0\n",
    "\n",
    "print(f\"Train images shape: {train_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save checkpoint during training\n",
    "\n",
    "We can use a **trained model** without having to retrain it, or pick-up training where we left-off - in case the training process was interrupted. The `tf.keras.callbacks.ModelCheckpoint` callback allows to continually **save** the model both **during** and at **the end** of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint callback usage\n",
    "\n",
    "Here, only *during* training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 1.1813 - accuracy: 0.6649\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 1.1398 - accuracy: 0.6770 - val_loss: 0.7153 - val_accuracy: 0.7890\n",
      "Epoch 2/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.4242 - accuracy: 0.8877\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.4223 - accuracy: 0.8840 - val_loss: 0.5336 - val_accuracy: 0.8360\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2836 - accuracy: 0.9200\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2836 - accuracy: 0.9200 - val_loss: 0.4840 - val_accuracy: 0.8440\n",
      "Epoch 4/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.2163 - accuracy: 0.9558\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2195 - accuracy: 0.9520 - val_loss: 0.4412 - val_accuracy: 0.8590\n",
      "Epoch 5/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.1740 - accuracy: 0.9594\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9590 - val_loss: 0.4153 - val_accuracy: 0.8630\n",
      "Epoch 6/10\n",
      "21/32 [==================>...........] - ETA: 0s - loss: 0.1147 - accuracy: 0.9807\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.9780 - val_loss: 0.4110 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.0850 - accuracy: 0.9915\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.9890 - val_loss: 0.4068 - val_accuracy: 0.8680\n",
      "Epoch 8/10\n",
      "22/32 [===================>..........] - ETA: 0s - loss: 0.0713 - accuracy: 0.9858\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0691 - accuracy: 0.9880 - val_loss: 0.4224 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.0547 - accuracy: 0.9946\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9950 - val_loss: 0.4205 - val_accuracy: 0.8640\n",
      "Epoch 10/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.0352 - accuracy: 1.0000\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f84791274a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with the callback created above\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(test_images, test_labels),\n",
    "          callbacks=[cp_callback]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **new untrained model**. When restoring a model from weights-only, you must have a model with **same architecture as the original model**. Since it's the same architecture, we can share weights despite that it's a different *instance* of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.4502 - accuracy: 0.1630\n",
      "Untrained model accuracy: 16.30%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Untrained model accuracy: {(100*acc):5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights from the checkpoint and re-evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4255 - accuracy: 0.8600\n",
      "Restored model accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "# Loads the weights\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Re-evaluate the model\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Restored model accuracy: {(100*acc):5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint callback options\n",
    "\n",
    "The callback provides several optionsto provide unique names for checkpoints and adjust the checkpointing frequency.\n",
    "\n",
    "Train a new model, and save uniquely named checkpoints once every five epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f845431e518>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 seconds\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1,\n",
    "    period=5\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "model.fit(train_images,\n",
    "          train_labels,\n",
    "          epochs=50,\n",
    "          callbacks=[cp_callback],\n",
    "          validation_data = (test_images, test_labels),\n",
    "          verbose=0\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t\t  cp-0025.ckpt.index\r\n",
      "cp-0000.ckpt.data-00000-of-00001  cp-0030.ckpt.data-00000-of-00001\r\n",
      "cp-0000.ckpt.index\t\t  cp-0030.ckpt.index\r\n",
      "cp-0005.ckpt.data-00000-of-00001  cp-0035.ckpt.data-00000-of-00001\r\n",
      "cp-0005.ckpt.index\t\t  cp-0035.ckpt.index\r\n",
      "cp-0010.ckpt.data-00000-of-00001  cp-0040.ckpt.data-00000-of-00001\r\n",
      "cp-0010.ckpt.index\t\t  cp-0040.ckpt.index\r\n",
      "cp-0015.ckpt.data-00000-of-00001  cp-0045.ckpt.data-00000-of-00001\r\n",
      "cp-0015.ckpt.index\t\t  cp-0045.ckpt.index\r\n",
      "cp-0020.ckpt.data-00000-of-00001  cp-0050.ckpt.data-00000-of-00001\r\n",
      "cp-0020.ckpt.index\t\t  cp-0050.ckpt.index\r\n",
      "cp-0025.ckpt.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2/cp-0050.ckpt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test, reset the model and load the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4843 - accuracy: 0.8790\n",
      "Restored model accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.load_weights(latest)\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Restored model accuracy: {(100*acc):5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are these files?\n",
    "\n",
    "The checkpoint files contain the trained weights in binary format:\n",
    "- One or more shards that contain your model's weights\n",
    "- An index file that indicates which weights are stored in a which shard\n",
    "\n",
    "If you are only training a model on a single machine, you'll have one shard with the suffix: `.data-00000-of-00001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4843 - accuracy: 0.8790\n",
      "Restored model, accuracy: 87.90%\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Create a new model instance\n",
    "model = create_model()\n",
    "\n",
    "# Restore weights\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# Evaluate the model\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the entire model\n",
    "\n",
    "Call `model.save` to save a model's architecture, weights, and training configuration in a single file/folder. This allows us to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, we can resume training from exactly where we left off.\n",
    "\n",
    "Saving a fully-functional model is very usefulâ€”we can load them in TensorFlow.js and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SavedModel format\n",
    "\n",
    "The `SavedModel` format is another way to serialize models. Models saved in this format can be restored using `tf.keras.models.load_model` and are compatible with TensorFlow Serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1817 - accuracy: 0.6570\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8770\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.9270\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2032 - accuracy: 0.9540\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9660\n",
      "WARNING:tensorflow:From /home/nxhuy/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\r\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tsaved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": [
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reload\n",
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4280 - accuracy: 0.8580\n",
      "Restored model, accuracy: 85.80%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 format\n",
    "\n",
    "Keras saves models by inspecting the architecture. This technique saves everything:\n",
    "\n",
    "- The weight values\n",
    "- The model's architecture\n",
    "- The model's training configuration(what you passed to compile)\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1998 - accuracy: 0.6620\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3074 - accuracy: 0.9110\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2238 - accuracy: 0.9470\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.9710\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('my_model.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4108 - accuracy: 0.8690\n",
      "Restored model, accuracy: 86.90%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving custom objects\n",
    "\n",
    "The key difference between HDF5 and SavedModel is that **HDF5** uses **object configs** to save the model architecture, while **SavedModel** saves the **execution graph**. Thus, **SavedModel**s are able to save **custom objects like subclassed models and custom layers** without requiring the orginal code.\n",
    "\n",
    "\n",
    "To **save custom objects to HDF5**, you must do the following:\n",
    "\n",
    "- Define a `get_config` method in your object, and optionally a `from_config` classmethod.\n",
    "    - `get_config(self)` returns a JSON-serializable dictionary of parameters needed to recreate the object.\n",
    "    - `from_config(cls, config)` uses the returned config from `get_config` to create a new object. By default, this function will use the config as initialization kwargs (`return cls(**config)`).\n",
    "- Pass the object to the `custom_objects` argument when loading the model. The argument must be a dictionary mapping the string class name to the Python class. E.g. `tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
